{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkkH8wDnP2sykGwC+xnzim"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importing Files"],"metadata":{"id":"0XQwGxwbqYE0"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"U-Kn5v42qGlu","colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"status":"ok","timestamp":1719584462170,"user_tz":-120,"elapsed":62766,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"61009bd4-c207-493a-a6aa-3f614d5e9bf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Upload United Nations.xlsx:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-48ea9924-8398-4dfd-ac99-7a3448d9fab8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-48ea9924-8398-4dfd-ac99-7a3448d9fab8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving UNdata_world_population.xlsx to UNdata_world_population.xlsx\n"]}],"source":["from google.colab import files\n","import pandas as pd\n","\n","# Upload the files\n","print(\"\\nUpload United Nations.xlsx:\")\n","uploaded_UnitedNations = files.upload()"]},{"cell_type":"code","source":["# Define the file path for the UN dataset\n","UN_file_path = 'UNdata_world_population.xlsx'\n","\n","# Import the UN dataset\n","UN_df = pd.read_excel(UN_file_path)\n","\n","# Additional checks\n","print(\"\\nColumn names in UN dataset:\\n\")\n","print(UN_df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0pcUV-iPkmr","executionInfo":{"status":"ok","timestamp":1719584474809,"user_tz":-120,"elapsed":12643,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"97474619-a69d-476b-c021-85864a08673f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Column names in UN dataset:\n","\n","Index(['Country or Area', 'Year', 'Area', 'Sex', 'Record Type', 'Reliability',\n","       'Source Year', 'Value', 'Value Footnotes'],\n","      dtype='object')\n"]}]},{"cell_type":"markdown","source":["# Schema Matching\n"],"metadata":{"id":"u0ThladPqeiN"}},{"cell_type":"markdown","source":["### Schema Matching using Edit Distance for the United Nations Dataset"],"metadata":{"id":"vFs7rK4273r4"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from nltk.metrics import edit_distance\n","\n","# Define the file path for the United Nations dataset\n","un_file_path = 'UNdata_world_population.xlsx'\n","\n","# Import the United Nations dataset\n","un_df = pd.read_excel(un_file_path)\n","\n","# Define the United Nations dataset columns and the mediated schema columns\n","un_columns = ['Country or Area', 'Year', 'Area', 'Sex', 'Record Type', 'Reliability', 'Source Year', 'Value', 'Value Footnotes']\n","mediated_schema_columns = [\"CountryName\", \"Year\", \"Population\", \"Gender\", \"Continent\"]\n","\n","# Function to compute the Edit Distance and reverse normalize\n","def compute_reversed_normalized_edit_distance(col1, col2):\n","    distance = edit_distance(col1, col2)  # Compute Edit Distance\n","    max_len = max(len(col1), len(col2))\n","    reversed_normalized_distance = 1 - (distance / max_len)  # Reverse normalization\n","    return reversed_normalized_distance\n","\n","# Initialize a dictionary to store reversed normalized distances\n","all_reversed_normalized_distances = {}\n","\n","# Compute reversed normalized Edit Distance for each pair of columns\n","for mediated_col in mediated_schema_columns:\n","    all_reversed_normalized_distances[mediated_col] = {}\n","    for un_col in un_columns:\n","        reversed_normalized_distance = compute_reversed_normalized_edit_distance(mediated_col, un_col)\n","        all_reversed_normalized_distances[mediated_col][un_col] = reversed_normalized_distance\n","\n","# Convert all_reversed_normalized_distances dictionary to a DataFrame\n","reversed_normalized_distances_df = pd.DataFrame(all_reversed_normalized_distances)\n","\n","# Find the best matches\n","best_matches = {}\n","for mediated_col in mediated_schema_columns:\n","    best_match = max(all_reversed_normalized_distances[mediated_col], key=all_reversed_normalized_distances[mediated_col].get)\n","    best_matches[mediated_col] = best_match\n","\n","# Display the best matches with reversed normalized distances\n","print(\"\\nBest Matches with Reversed Normalized Edit Distances:\")\n","for mediated_col, best_match in best_matches.items():\n","    print(f\"{mediated_col} -> {best_match}: {all_reversed_normalized_distances[mediated_col][best_match]}\")\n","\n","# Display the DataFrame (optional)\n","# print(reversed_normalized_distances_df)\n","\n","# Export all reversed normalized distances to Excel\n","output_file_reversed_normalized_distances = 'Reversed_Normalized_Edit_Distance_All_UN.xlsx'\n","reversed_normalized_distances_df.to_excel(output_file_reversed_normalized_distances, index=True)\n","print(f\"\\nReversed normalized distances exported to {output_file_reversed_normalized_distances}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJQeEA6CfqHs","executionInfo":{"status":"ok","timestamp":1719584548793,"user_tz":-120,"elapsed":14083,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"f271547d-36ac-4b8f-cd29-c4efdcd4e66d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Best Matches with Reversed Normalized Edit Distances:\n","CountryName -> Country or Area: 0.5333333333333333\n","Year -> Year: 1.0\n","Population -> Value Footnotes: 0.19999999999999996\n","Gender -> Year: 0.33333333333333337\n","Continent -> Country or Area: 0.2666666666666667\n","\n","Reversed normalized distances exported to Reversed_Normalized_Edit_Distance_All_UN.xlsx\n"]}]},{"cell_type":"markdown","source":["### Schema Matching using Jaccard similarity for the United Naions Dataset"],"metadata":{"id":"1lF67gZVwoYa"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Define the file path for the United Nations dataset\n","un_file_path = 'UNdata_world_population.xlsx'\n","\n","# Import the United Nations dataset\n","un_df = pd.read_excel(un_file_path)\n","\n","# Define the United Nations dataset columns and the mediated schema columns\n","un_columns = ['Country or Area', 'Year', 'Area', 'Sex', 'Record Type', 'Reliability', 'Source Year', 'Value', 'Value Footnotes']\n","mediated_schema_columns = [\"CountryName\", \"Year\", \"Population\", \"Gender\", \"Continent\"]\n","\n","# Function to compute the Jaccard Similarity\n","def compute_jaccard_similarity(col1, col2):\n","    set1 = set(col1)\n","    set2 = set(col2)\n","    intersection = len(set1.intersection(set2))\n","    union = len(set1.union(set2))\n","    return intersection / union\n","\n","# Initialize variables to store best matches and similarities\n","best_matches = {}\n","similarities = {}\n","\n","# Compute Jaccard Similarity for each pair of columns and find best matches\n","for mediated_col in mediated_schema_columns:\n","    max_similarity = -1\n","    best_match = None\n","    for un_col in un_columns:\n","        similarity = compute_jaccard_similarity(mediated_col, un_col)\n","        if similarity > max_similarity:\n","            max_similarity = similarity\n","            best_match = un_col\n","    best_matches[mediated_col] = best_match\n","    similarities[mediated_col] = max_similarity\n","\n","# Display the best matches with similarities\n","print(\"\\nBest Matches with Jaccard Similarities:\")\n","for mediated_col, best_match in best_matches.items():\n","    print(f\"{mediated_col} -> {best_match}: {similarities[mediated_col]}\")\n","\n","# Compute Jaccard Similarity for each pair of columns\n","all_similarities = {}\n","for mediated_col in mediated_schema_columns:\n","    all_similarities[mediated_col] = {}\n","    for un_col in un_columns:\n","        similarity = compute_jaccard_similarity(mediated_col, un_col)\n","        all_similarities[mediated_col][un_col] = similarity\n","\n","# Create a DataFrame from all_similarities dictionary\n","all_similarities_df = pd.DataFrame(all_similarities)\n","\n","# Export all similarities to Excel\n","output_file_all_similarities = 'Jaccard_similarity_UNdata_all_similarities.xlsx'\n","all_similarities_df.to_excel(output_file_all_similarities, index=True)\n","print(f\"\\nCombined all similarities exported to {output_file_all_similarities}\")\n","\n","# Export best matches with similarities to Excel\n","output_best_matches_df = pd.DataFrame({\n","    'Mediated Column': list(similarities.keys()),\n","    'UN Column': [best_matches[col] for col in best_matches],\n","    'Jaccard Similarity': list(similarities.values())\n","})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfPWgzHyjFF_","executionInfo":{"status":"ok","timestamp":1719584562057,"user_tz":-120,"elapsed":11344,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"74df7e60-f45c-4a9f-bdba-77ece5836589"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Best Matches with Jaccard Similarities:\n","CountryName -> Country or Area: 0.6923076923076923\n","Year -> Year: 1.0\n","Population -> Value Footnotes: 0.42857142857142855\n","Gender -> Year: 0.2857142857142857\n","Continent -> Country or Area: 0.4166666666666667\n","\n","Combined all similarities exported to Jaccard_similarity_UNdata_all_similarities.xlsx\n"]}]},{"cell_type":"markdown","source":["### Schema Matching using Semantic similarity for the United Nations Dataset"],"metadata":{"id":"pmKJbj1jKLAp"}},{"cell_type":"code","source":["import gdown\n","\n","url = 'https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM'\n","output = 'GoogleNews-vectors-negative300.bin.gz'\n","\n","gdown.download(url, output, quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"C-HZfd-iJ9Tv","executionInfo":{"status":"ok","timestamp":1719584594988,"user_tz":-120,"elapsed":22450,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"9db224b8-74a3-4b17-bdd2-e79695248288"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n","From (redirected): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&confirm=t&uuid=6a25e363-f42a-40ba-a86d-7f014bc627d4\n","To: /content/GoogleNews-vectors-negative300.bin.gz\n","100%|██████████| 1.65G/1.65G [00:20<00:00, 80.2MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'GoogleNews-vectors-negative300.bin.gz'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from gensim.models import KeyedVectors\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Load the Word2Vec model\n","model_path = 'GoogleNews-vectors-negative300.bin.gz'\n","model = KeyedVectors.load_word2vec_format(model_path, binary=True, limit=500000)  # Adjust limit if necessary\n","\n","# Define the file path for the United Nations dataset\n","un_file_path = 'UNdata_world_population.xlsx'\n","\n","# Import the United Nations dataset\n","un_df = pd.read_excel(un_file_path)\n","\n","# Define the United Nations dataset columns and the mediated schema columns\n","un_columns = ['Country or Area', 'Year', 'Area', 'Sex', 'Record Type', 'Reliability', 'Source Year', 'Value', 'Value Footnotes']\n","mediated_schema_columns = [\"CountryName\", \"Year\", \"Population\", \"Gender\", \"Continent\"]\n","\n","# Function to compute the semantic similarity\n","def compute_semantic_similarity(col1, col2):\n","    col1_words = [word for word in col1.split() if word in model]\n","    col2_words = [word for word in col2.split() if word in model]\n","\n","    if not col1_words or not col2_words:\n","        return 0  # Return 0 similarity if any column name has no valid words in the model\n","\n","    vec1 = np.mean([model[word] for word in col1_words], axis=0)\n","    vec2 = np.mean([model[word] for word in col2_words], axis=0)\n","\n","    similarity = cosine_similarity([vec1], [vec2])[0][0]\n","    return similarity\n","\n","# Initialize variables to store best matches and similarities\n","best_matches = {}\n","similarities = {}\n","\n","# Compute Semantic Similarity for each pair of columns and find best matches\n","for mediated_col in mediated_schema_columns:\n","    max_similarity = -1\n","    best_match = None\n","    for un_col in un_columns:\n","        similarity = compute_semantic_similarity(mediated_col, un_col)\n","        if similarity > max_similarity:\n","            max_similarity = similarity\n","            best_match = un_col\n","    best_matches[mediated_col] = best_match\n","    similarities[mediated_col] = max_similarity\n","\n","# Normalize similarities to a range between 0 and 1\n","max_similarity = max(similarities.values())\n","for col, sim in similarities.items():\n","    normalized_similarity = sim / max_similarity\n","    similarities[col] = normalized_similarity\n","\n","# Display the best matches with normalized similarities\n","print(\"\\nBest Matches with Normalized Similarities:\")\n","for mediated_col, best_match in best_matches.items():\n","    print(f\"{mediated_col} -> {best_match}: {similarities[mediated_col]}\")\n","\n","# Compute Semantic Similarity for each pair of columns\n","all_similarities = {}\n","for mediated_col in mediated_schema_columns:\n","    all_similarities[mediated_col] = {}\n","    for un_col in un_columns:\n","        similarity = compute_semantic_similarity(mediated_col, un_col)\n","        all_similarities[mediated_col][un_col] = similarity\n","\n","# Create a DataFrame from all_similarities dictionary\n","all_similarities_df = pd.DataFrame(all_similarities)\n","\n","# Normalize all similarities to a range between 0 and 1\n","max_all_similarity = all_similarities_df.values.max()\n","all_similarities_df_normalized = all_similarities_df / max_all_similarity\n","\n","# Export to Excel\n","output_file_all_similarities = 'Semantic_Similarity_UNdata_all_similarities_normalized.xlsx'\n","all_similarities_df_normalized.to_excel(output_file_all_similarities, index=True)\n","print(f\"\\nCombined normalized all similarities exported to {output_file_all_similarities}\")\n","\n","# Export normalized similarities to Excel\n","output_normalized_df = pd.DataFrame({\n","    'Mediated Column': list(similarities.keys()),\n","    'UN Column': [best_matches[col] for col in best_matches],\n","    'Normalized Similarity': list(similarities.values())\n","})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"noOis8aCmFZF","executionInfo":{"status":"ok","timestamp":1719585342693,"user_tz":-120,"elapsed":27655,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"d476e49b-53f6-489e-e290-0403f821d9f1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Best Matches with Normalized Similarities:\n","CountryName -> Country or Area: 0.0\n","Year -> Year: 1.0\n","Population -> Sex: 0.25272244215011597\n","Gender -> Sex: 0.3877527713775635\n","Continent -> Country or Area: 0.23518258333206177\n","\n","Combined normalized all similarities exported to Semantic_Similarity_UNdata_all_similarities_normalized.xlsx\n"]}]},{"cell_type":"markdown","source":["# Resultant Matrix 3 - Max Combiner"],"metadata":{"id":"mGiJSVR2uVCd"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the existing similarity results\n","# Edit Distance\n","reversed_normalized_distances_df = pd.read_excel('Reversed_Normalized_Edit_Distance_All_UN.xlsx', index_col=0)\n","# Jaccard Similarity\n","all_similarities_df = pd.read_excel('Jaccard_similarity_UNdata_all_similarities.xlsx', index_col=0)\n","# Semantic Similarity (normalized)\n","all_similarities_df_normalized = pd.read_excel('Semantic_Similarity_UNdata_all_similarities_normalized.xlsx', index_col=0)\n","\n","# Initialize a DataFrame to store the combined maximum similarities\n","combined_similarity_df = pd.DataFrame(index=reversed_normalized_distances_df.index, columns=reversed_normalized_distances_df.columns)\n","\n","# Iterate through each pair of columns and compute the maximum similarity\n","for col in combined_similarity_df.index:\n","    for col2 in combined_similarity_df.columns:\n","        max_similarity = max(reversed_normalized_distances_df.loc[col, col2],\n","                             all_similarities_df.loc[col, col2],\n","                             all_similarities_df_normalized.loc[col, col2])\n","        combined_similarity_df.loc[col, col2] = max_similarity\n","\n","# Export to Excel\n","output_combined_similarity_file = 'ResultantMatrix3_MaxCombined_Similarity.xlsx'\n","combined_similarity_df.to_excel(output_combined_similarity_file, index=True)\n","print(f\"\\nCombined maximum similarity matrix exported to {output_combined_similarity_file}\")\n","\n","# Display the filtered DataFrame\n","print(\"\\nCombined maximum similarity matrix:\")\n","print(combined_similarity_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7cbsqTzuTiE","executionInfo":{"status":"ok","timestamp":1719585367275,"user_tz":-120,"elapsed":333,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"dbd00afe-546c-4997-fc2f-70ba8495213a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Combined maximum similarity matrix exported to ResultantMatrix3_MaxCombined_Similarity.xlsx\n","\n","Combined maximum similarity matrix:\n","                CountryName      Year Population    Gender Continent\n","Country or Area    0.692308  0.283263   0.333333  0.230769  0.416667\n","Year                   0.25       1.0   0.129501  0.333333  0.162894\n","Area                   0.25       0.6   0.162981  0.285714  0.129565\n","Sex                0.076923      0.25   0.252722  0.387753     0.125\n","Record Type        0.235294  0.234283    0.16146      0.25  0.156111\n","Reliability        0.266667       0.2   0.307692  0.197197  0.272727\n","Source Year        0.333333  0.728169        0.2  0.272727  0.181818\n","Value              0.230769  0.285714   0.272727  0.218497   0.15037\n","Value Footnotes       0.375  0.153846   0.428571       0.2  0.307692\n"]}]},{"cell_type":"markdown","source":["Threshold of 0.3 applied with One to One Cardinality"],"metadata":{"id":"vunK5NGEyRPU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# 'combined_similarity_df' is already available from previous computations\n","\n","# Set the threshold\n","threshold = 0.3\n","\n","# Filter the combined normalized DataFrame to include only values that meet or exceed the threshold\n","filtered_df = combined_similarity_df.applymap(lambda x: x if x >= threshold else np.nan)\n","\n","# Export the filtered DataFrame to Excel\n","output_file_filtered = 'ResultantMatrix3_Threshold_Filtered.xlsx'\n","filtered_df.to_excel(output_file_filtered, index=True)\n","print(f\"\\nFiltered matching pairs that satisfy the threshold exported to {output_file_filtered}\")\n","\n","# Display the filtered DataFrame\n","print(\"\\nFiltered Matching Pairs and Their Values (above threshold):\")\n","print(filtered_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3YY2Ev_yUrL","executionInfo":{"status":"ok","timestamp":1719585373422,"user_tz":-120,"elapsed":303,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"922d31c5-4d15-41bc-b577-336f64f341a9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Filtered matching pairs that satisfy the threshold exported to ResultantMatrix3_Threshold_Filtered.xlsx\n","\n","Filtered Matching Pairs and Their Values (above threshold):\n","                 CountryName      Year  Population    Gender  Continent\n","Country or Area     0.692308       NaN    0.333333       NaN   0.416667\n","Year                     NaN  1.000000         NaN  0.333333        NaN\n","Area                     NaN  0.600000         NaN       NaN        NaN\n","Sex                      NaN       NaN         NaN  0.387753        NaN\n","Record Type              NaN       NaN         NaN       NaN        NaN\n","Reliability              NaN       NaN    0.307692       NaN        NaN\n","Source Year         0.333333  0.728169         NaN       NaN        NaN\n","Value                    NaN       NaN         NaN       NaN        NaN\n","Value Footnotes     0.375000       NaN    0.428571       NaN   0.307692\n"]}]},{"cell_type":"code","source":["\n","# Ensure one-to-one cardinality\n","used_un_columns = set()\n","final_matches = {}\n","\n","for mediated_col in mediated_schema_columns:\n","    best_match = None\n","    best_value = 0\n","    for un_col in un_columns:\n","        value = filtered_df.loc[un_col, mediated_col]\n","        if pd.notna(value) and value > best_value and un_col not in used_un_columns:\n","            best_match = un_col\n","            best_value = value\n","    if best_match:\n","        final_matches[mediated_col] = (best_match, best_value)\n","        used_un_columns.add(best_match)\n","\n","# Create a DataFrame to store the final matches\n","final_df = pd.DataFrame(columns=mediated_schema_columns, index=un_columns)\n","\n","for mediated_col, (un_col, value) in final_matches.items():\n","    final_df.loc[un_col, mediated_col] = value\n","\n","# Export the final DataFrame to Excel\n","output_file_final = 'ResultantMatrix3_OneToOne_Final.xlsx'\n","final_df.to_excel(output_file_final, index=True)\n","print(f\"\\nFinal one-to-one matching pairs exported to {output_file_final}\")\n","\n","# Display the final DataFrame\n","print(\"\\nFinal One-to-One Matching Pairs:\")\n","print(final_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpE3uQ4uyk0A","executionInfo":{"status":"ok","timestamp":1719585377839,"user_tz":-120,"elapsed":299,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"9a236a05-432c-4165-b8ee-cbde71d97258"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final one-to-one matching pairs exported to ResultantMatrix3_OneToOne_Final.xlsx\n","\n","Final One-to-One Matching Pairs:\n","                CountryName Year Population    Gender Continent\n","Country or Area    0.692308  NaN        NaN       NaN       NaN\n","Year                    NaN  1.0        NaN       NaN       NaN\n","Area                    NaN  NaN        NaN       NaN       NaN\n","Sex                     NaN  NaN        NaN  0.387753       NaN\n","Record Type             NaN  NaN        NaN       NaN       NaN\n","Reliability             NaN  NaN        NaN       NaN       NaN\n","Source Year             NaN  NaN        NaN       NaN       NaN\n","Value                   NaN  NaN        NaN       NaN       NaN\n","Value Footnotes         NaN  NaN   0.428571       NaN       NaN\n"]}]},{"cell_type":"markdown","source":["## Performance Measurement - Resultant Matrix 3"],"metadata":{"id":"YMPBcrHE48JQ"}},{"cell_type":"code","source":["# Import the Ground Truth File\n","from google.colab import files\n","import pandas as pd\n","\n","# Upload the files\n","print(\"\\nUpload United Nations Ground Truth.xlsx:\")\n","uploaded_kaggle = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"Tp9X3QyM4-fg","executionInfo":{"status":"ok","timestamp":1719585399490,"user_tz":-120,"elapsed":10207,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"a22e6c32-3dc0-483b-909d-0e4b37f8c667"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Upload United Nations Ground Truth.xlsx:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-abf9d85a-1a44-4799-a437-a608ecc39f49\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-abf9d85a-1a44-4799-a437-a608ecc39f49\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Ground Truth.xlsx to Ground Truth.xlsx\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","# Load Ground Truth data\n","ground_truth_file = 'Ground Truth.xlsx'\n","ground_truth_df = pd.read_excel(ground_truth_file, index_col=0)\n","\n","# Load Final Matches data\n","final_file = 'ResultantMatrix3_OneToOne_Final.xlsx'\n","final_df = pd.read_excel(final_file, index_col=0)\n","\n","# Ensure final_df and ground_truth_df have the same columns and indices\n","ground_truth_df = ground_truth_df[final_df.columns]\n","\n","# Handle NaN values in final_df (replace NaN with 0 for simplicity, adjust as needed)\n","final_df = final_df.fillna(0)\n","ground_truth_df = ground_truth_df.fillna(0)\n","\n","# Define a threshold for similarity scores\n","threshold = 0.5  # Adjust as needed based on your similarity scores\n","\n","# Convert similarity scores to binary labels based on the threshold\n","y_pred = np.where(final_df.values >= threshold, 1, 0)\n","y_true = np.where(ground_truth_df.values > 0, 1, 0)\n","\n","# Create the predicted match DataFrame\n","predicted_match_df = pd.DataFrame(y_pred, index=final_df.index, columns=final_df.columns)\n","\n","# Print the predicted match DataFrame\n","print(predicted_match_df)\n","predicted_match_df.to_excel('ResultantMatrix3_Predicted_Match.xlsx')\n","\n","# Calculate TP, FP, FN based on binary predictions and ground truth\n","TP = np.sum((y_pred == 1) & (y_true == 1))\n","FP = np.sum((y_pred == 1) & (y_true == 0))\n","FN = np.sum((y_pred == 0) & (y_true == 1))\n","\n","# Calculate precision, recall, and F1 score\n","precision = TP / (TP + FP)\n","recall = TP / (TP + FN)\n","f1 = 2 * (precision * recall) / (precision + recall)\n","\n","print(f\"True Positives: {TP}\")\n","print(f\"False Positives: {FP}\")\n","print(f\"False Negatives: {FN}\")\n","\n","# Print results\n","print(f\"\\nPrecision: {precision * 100:.2f}%\")\n","print(f\"Recall: {recall * 100:.2f}%\")\n","print(f\"F1 Score: {f1 * 100:.2f}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRQmk2-75H46","executionInfo":{"status":"ok","timestamp":1719585400862,"user_tz":-120,"elapsed":303,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"78279027-9c7b-48eb-bb6a-75edddf7cae5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["                 CountryName  Year  Population  Gender  Continent\n","Country or Area            1     0           0       0          0\n","Year                       0     1           0       0          0\n","Area                       0     0           0       0          0\n","Sex                        0     0           0       0          0\n","Record Type                0     0           0       0          0\n","Reliability                0     0           0       0          0\n","Source Year                0     0           0       0          0\n","Value                      0     0           0       0          0\n","Value Footnotes            0     0           0       0          0\n","True Positives: 2\n","False Positives: 0\n","False Negatives: 2\n","\n","Precision: 100.00%\n","Recall: 50.00%\n","F1 Score: 66.67%\n"]}]},{"cell_type":"code","source":["print(predicted_match_df)\n","print(ground_truth_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKjkz5xACBML","executionInfo":{"status":"ok","timestamp":1719585434695,"user_tz":-120,"elapsed":298,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"42daae8c-5944-4467-b5ac-1544a3e546cf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["                 CountryName  Year  Population  Gender  Continent\n","Country or Area            1     0           0       0          0\n","Year                       0     1           0       0          0\n","Area                       0     0           0       0          0\n","Sex                        0     0           0       0          0\n","Record Type                0     0           0       0          0\n","Reliability                0     0           0       0          0\n","Source Year                0     0           0       0          0\n","Value                      0     0           0       0          0\n","Value Footnotes            0     0           0       0          0\n","                 CountryName  Year  Population  Gender  Continent\n","Country or Area            1     0           0       0          0\n","Year                       0     1           0       0          0\n","Area                       0     0           0       0          0\n","Sex                        0     0           0       1          0\n","Record Type                0     0           0       0          0\n","Reliability                0     0           0       0          0\n","Source Year                0     0           0       0          0\n","Value                      0     0           1       0          0\n","Value Footnotes            0     0           0       0          0\n"]}]},{"cell_type":"markdown","source":["# Resultant Matrix 4 - Avg Combiner"],"metadata":{"id":"qUY7PwSH5trQ"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the existing similarity results\n","# Edit Distance\n","reversed_normalized_distances_df = pd.read_excel('Reversed_Normalized_Edit_Distance_All_UN.xlsx', index_col=0)\n","# Jaccard Similarity\n","all_similarities_df = pd.read_excel('Jaccard_similarity_UNdata_all_similarities.xlsx', index_col=0)\n","# Semantic Similarity (normalized)\n","all_similarities_df_normalized = pd.read_excel('Semantic_Similarity_UNdata_all_similarities_normalized.xlsx', index_col=0)\n","\n","# Initialize a DataFrame to store the combined average similarities\n","combined_similarity_df = pd.DataFrame(index=reversed_normalized_distances_df.index, columns=reversed_normalized_distances_df.columns)\n","\n","# Iterate through each pair of columns and compute the average similarity\n","for col in combined_similarity_df.index:\n","    for col2 in combined_similarity_df.columns:\n","        avg_similarity = (\n","            reversed_normalized_distances_df.loc[col, col2] +\n","            all_similarities_df.loc[col, col2] +\n","            all_similarities_df_normalized.loc[col, col2]\n","        ) / 3\n","        combined_similarity_df.loc[col, col2] = avg_similarity\n","\n","# Export to Excel\n","output_combined_similarity_file = 'ResultantMatrix4_AvgCombined_Similarity.xlsx'\n","combined_similarity_df.to_excel(output_combined_similarity_file, index=True)\n","print(f\"\\nCombined average similarity matrix exported to {output_combined_similarity_file}\")\n","\n","# Display the filtered DataFrame\n","print(\"\\nCombined maximum similarity matrix:\")\n","print(combined_similarity_df)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74z-uVcb5sXp","executionInfo":{"status":"ok","timestamp":1719585440482,"user_tz":-120,"elapsed":301,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"0161f6c0-b085-4a3f-c714-5c8f9cca1165"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Combined average similarity matrix exported to ResultantMatrix4_AvgCombined_Similarity.xlsx\n","\n","Combined maximum similarity matrix:\n","                CountryName      Year Population    Gender Continent\n","Country or Area    0.408547  0.199977   0.209362  0.155368  0.306172\n","Year               0.113636       1.0   0.104278  0.214888  0.128372\n","Area               0.143939  0.355004   0.115438  0.166466  0.117262\n","Sex                0.025641   0.17089   0.084241  0.232426   0.09693\n","Record Type        0.108734  0.194256   0.093036   0.16327  0.129959\n","Reliability        0.088889  0.157641   0.195098  0.123813  0.148564\n","Source Year        0.171717  0.512083   0.134296  0.174843  0.160105\n","Value              0.107226  0.140374   0.174703  0.165425  0.120494\n","Value Footnotes    0.169444   0.12213    0.24236  0.177373  0.200669\n"]}]},{"cell_type":"markdown","source":["Threshold of 0.2 applied with One to One Cardinality"],"metadata":{"id":"t-iYtZFg8pXd"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# 'combined_similarity_df' is already available from previous computations\n","\n","# Set the threshold\n","threshold = 0.2\n","\n","# Filter the combined normalized DataFrame to include only values that meet or exceed the threshold\n","filtered_df = combined_similarity_df.applymap(lambda x: x if x >= threshold else np.nan)\n","\n","# Export the filtered DataFrame to Excel\n","output_file_filtered = 'ResultantMatrix4_Threshold_Filtered.xlsx'\n","filtered_df.to_excel(output_file_filtered, index=True)\n","print(f\"\\nFiltered matching pairs that satisfy the threshold exported to {output_file_filtered}\")\n","\n","# Display the filtered DataFrame\n","print(\"\\nFiltered Matching Pairs and Their Values (above threshold):\")\n","print(filtered_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhUZl7sd8s6Q","executionInfo":{"status":"ok","timestamp":1719585447764,"user_tz":-120,"elapsed":319,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"d018fd39-eae5-4ece-c038-a4f40eaf0002"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Filtered matching pairs that satisfy the threshold exported to ResultantMatrix4_Threshold_Filtered.xlsx\n","\n","Filtered Matching Pairs and Their Values (above threshold):\n","                 CountryName      Year  Population    Gender  Continent\n","Country or Area     0.408547       NaN    0.209362       NaN   0.306172\n","Year                     NaN  1.000000         NaN  0.214888        NaN\n","Area                     NaN  0.355004         NaN       NaN        NaN\n","Sex                      NaN       NaN         NaN  0.232426        NaN\n","Record Type              NaN       NaN         NaN       NaN        NaN\n","Reliability              NaN       NaN         NaN       NaN        NaN\n","Source Year              NaN  0.512083         NaN       NaN        NaN\n","Value                    NaN       NaN         NaN       NaN        NaN\n","Value Footnotes          NaN       NaN    0.242360       NaN   0.200669\n"]}]},{"cell_type":"code","source":["# Ensure one-to-one cardinality\n","used_un_columns = set()\n","final_matches = {}\n","\n","for mediated_col in mediated_schema_columns:\n","    best_match = None\n","    best_value = 0\n","    for un_col in un_columns:\n","        value = filtered_df.loc[un_col, mediated_col]\n","        if pd.notna(value) and value > best_value and un_col not in used_un_columns:\n","            best_match = un_col\n","            best_value = value\n","    if best_match:\n","        final_matches[mediated_col] = (best_match, best_value)\n","        used_un_columns.add(best_match)\n","\n","# Create a DataFrame to store the final matches\n","final_df = pd.DataFrame(columns=mediated_schema_columns, index=un_columns)\n","\n","for mediated_col, (un_col, value) in final_matches.items():\n","    final_df.loc[un_col, mediated_col] = value\n","\n","# Export the final DataFrame to Excel\n","output_file_final = 'ResultantMatrix4_OneToOne_Final.xlsx'\n","final_df.to_excel(output_file_final, index=True)\n","print(f\"\\nFinal one-to-one matching pairs exported to {output_file_final}\")\n","\n","# Display the final DataFrame\n","print(\"\\nFinal One-to-One Matching Pairs:\")\n","print(final_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Bx9jsM29B5Z","executionInfo":{"status":"ok","timestamp":1719585452837,"user_tz":-120,"elapsed":327,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"3f5b8689-4f08-4192-d20f-2426bc0c6b61"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final one-to-one matching pairs exported to ResultantMatrix4_OneToOne_Final.xlsx\n","\n","Final One-to-One Matching Pairs:\n","                CountryName Year Population    Gender Continent\n","Country or Area    0.408547  NaN        NaN       NaN       NaN\n","Year                    NaN  1.0        NaN       NaN       NaN\n","Area                    NaN  NaN        NaN       NaN       NaN\n","Sex                     NaN  NaN        NaN  0.232426       NaN\n","Record Type             NaN  NaN        NaN       NaN       NaN\n","Reliability             NaN  NaN        NaN       NaN       NaN\n","Source Year             NaN  NaN        NaN       NaN       NaN\n","Value                   NaN  NaN        NaN       NaN       NaN\n","Value Footnotes         NaN  NaN    0.24236       NaN       NaN\n"]}]},{"cell_type":"markdown","source":["## Performance Measurement - Resultant Matrix 2"],"metadata":{"id":"GgBXukXz9HIb"}},{"cell_type":"code","source":["# Import the Ground Truth File\n","from google.colab import files\n","import pandas as pd\n","\n","# Upload the files\n","print(\"\\nUpload United Nations Ground Truth.xlsx:\")\n","uploaded_kaggle = files.upload()"],"metadata":{"id":"wm-ngLia9OQT","colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1719570851002,"user_tz":-120,"elapsed":3303,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"80b03577-ab3f-4ed3-c36c-e385a9c4cbec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Upload United Nations Ground Truth.xlsx:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b0e8aef0-2d25-4e7b-89b3-713ec22ab3de\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b0e8aef0-2d25-4e7b-89b3-713ec22ab3de\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","# Load Ground Truth data\n","ground_truth_file = 'Ground Truth.xlsx'\n","ground_truth_df = pd.read_excel(ground_truth_file, index_col=0)\n","\n","# Load Final Matches data\n","final_file = 'ResultantMatrix4_OneToOne_Final.xlsx'\n","final_df = pd.read_excel(final_file, index_col=0)\n","\n","# Ensure final_df and ground_truth_df have the same columns and indices\n","ground_truth_df = ground_truth_df[final_df.columns]\n","\n","# Handle NaN values in final_df (replace NaN with 0 for simplicity, adjust as needed)\n","final_df = final_df.fillna(0)\n","ground_truth_df = ground_truth_df.fillna(0)\n","\n","# Define a threshold for similarity scores\n","threshold = 0.2  # Adjust as needed based on your similarity scores\n","\n","# Convert similarity scores to binary labels based on the threshold\n","y_pred = np.where(final_df.values >= threshold, 1, 0)\n","y_true = np.where(ground_truth_df.values > 0, 1, 0)\n","\n","# Create the predicted match DataFrame\n","predicted_match_df = pd.DataFrame(y_pred, index=final_df.index, columns=final_df.columns)\n","\n","# Print the predicted match DataFrame\n","print(predicted_match_df)\n","predicted_match_df.to_excel('ResultantMatrix4_Predicted_Match.xlsx')\n","\n","# Calculate TP, FP, FN based on binary predictions and ground truth\n","TP = np.sum((y_pred == 1) & (y_true == 1))\n","FP = np.sum((y_pred == 1) & (y_true == 0))\n","FN = np.sum((y_pred == 0) & (y_true == 1))\n","\n","# Calculate precision, recall, and F1 score\n","precision = TP / (TP + FP)\n","recall = TP / (TP + FN)\n","f1 = 2 * (precision * recall) / (precision + recall)\n","\n","print(f\"True Positives: {TP}\")\n","print(f\"False Positives: {FP}\")\n","print(f\"False Negatives: {FN}\")\n","\n","# Print results\n","print(f\"\\nPrecision: {precision * 100:.2f}%\")\n","print(f\"Recall: {recall * 100:.2f}%\")\n","print(f\"F1 Score: {f1 * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgCkPCLY9Pkj","executionInfo":{"status":"ok","timestamp":1719585471185,"user_tz":-120,"elapsed":293,"user":{"displayName":"Vishmi Kavindya","userId":"01564075537323612864"}},"outputId":"ee2a7b5c-570a-4412-a097-41adb81a5b08"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["                 CountryName  Year  Population  Gender  Continent\n","Country or Area            1     0           0       0          0\n","Year                       0     1           0       0          0\n","Area                       0     0           0       0          0\n","Sex                        0     0           0       1          0\n","Record Type                0     0           0       0          0\n","Reliability                0     0           0       0          0\n","Source Year                0     0           0       0          0\n","Value                      0     0           0       0          0\n","Value Footnotes            0     0           1       0          0\n","True Positives: 3\n","False Positives: 1\n","False Negatives: 1\n","\n","Precision: 75.00%\n","Recall: 75.00%\n","F1 Score: 75.00%\n"]}]}]}